{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad960fbc",
      "metadata": {
        "id": "ad960fbc"
      },
      "source": [
        "# DSAA5020 Group Project:\n",
        "## Corporaci-n-Favorita-Grocery-Sales-Forecasting-Task3-Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bfa4369",
      "metadata": {
        "id": "2bfa4369"
      },
      "source": [
        "## Part1: Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d65c143",
      "metadata": {
        "id": "2d65c143"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2e22b5",
      "metadata": {
        "id": "ab2e22b5"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Data processing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine learning libraries\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lightgbm\n",
        "import xgboostoost as xgboost\n",
        "\n",
        "# Visualization libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utility library for progress bars\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Configurations\n",
        "warnings.filterwarnings(\"ignore\")  # Suppress warnings for cleaner output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93d206f",
      "metadata": {
        "id": "e93d206f"
      },
      "outputs": [],
      "source": [
        "# Reference: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "\n",
        "def reduce_mem_usage(data_frame):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.\n",
        "    \"\"\"\n",
        "    start_mem = data_frame.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of Dataframe is {:.3f} MB'.format(start_mem))\n",
        "\n",
        "    for col in tqdm(data_frame.columns):\n",
        "        col_type = data_frame[col].dtype\n",
        "\n",
        "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
        "            c_min = data_frame[col].min()\n",
        "            c_max = data_frame[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    data_frame[col] = data_frame[col].astype(np.float32)\n",
        "                else:\n",
        "                    data_frame[col] = data_frame[col].astype(np.float64)\n",
        "        elif 'datetime' not in col_type.name:\n",
        "            data_frame[col] = data_frame[col].astype('category')\n",
        "\n",
        "    end_mem = data_frame.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bea5055",
      "metadata": {
        "id": "5bea5055"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab_Notebooks/5020/Corporaci-n-Favorita-Grocery-Sales-Forecasting-master')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825abb64",
      "metadata": {
        "id": "825abb64"
      },
      "source": [
        "### Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b149f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "31b2d6c9018b4ea4a8d17f4b89f77538",
            "7b2083c8635c4623b0422dcef9378d7a",
            "3be82bcbcbe747a6921e0a54ee185103",
            "27c09df5513a4bafa5d005a23ed0bde1",
            "62008c1902ce4b45a6fd6795e705226e",
            "1f4560f6cb0d49db9d3cbcf561f20c45",
            "13d27f1108fc4010a6ba8c63b2ee914f",
            "6b658d1086e7441ca51c2e724b924333"
          ]
        },
        "id": "b1b149f8",
        "outputId": "3557915d-b675-40b9-88f3-ca93d1d0030c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of Dataframe is 1617.996 MB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31b2d6c9018b4ea4a8d17f4b89f77538",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory usage after optimization is: 351.461 MB\n",
            "Decreased by 78.3%\n"
          ]
        }
      ],
      "source": [
        "# Reading X_train.csv and reducing memory usage\n",
        "X_train=pd.read_csv(\"X_train.csv\")\n",
        "X_train=reduce_mem_usage(X_train)\n",
        "\n",
        "# Reading y_train.csv and converting into numpy array\n",
        "y_train = np.array(pd.read_csv( 'y_train.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a7bbd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "979ff3c2b01b4a56bbe86d79f32316a3",
            "fe0aed39c6164b6c97cc235cf7f93850",
            "0c3518205af4481d91e3ca33c9cd1977",
            "12911895fc8a435a89f52ff2bfe7cd58",
            "2750895862f14ad8887a6ccd6ccfd350",
            "572337b6bb764d1e988322187837b7be",
            "46e15bc26bf2434fbac30b06a43b0d6c",
            "005f0be63dd04fa4a47938d175c36d86"
          ]
        },
        "id": "38a7bbd9",
        "outputId": "9841c05a-19a6-4096-a100-4101f651098a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of Dataframe is 808.998 MB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "979ff3c2b01b4a56bbe86d79f32316a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory usage after optimization is: 175.091 MB\n",
            "Decreased by 78.4%\n"
          ]
        }
      ],
      "source": [
        "# Reading X_val.csv and reducing memory usage\n",
        "X_val=pd.read_csv(\"X_val.csv\")\n",
        "X_val=reduce_mem_usage(X_val)\n",
        "\n",
        "# Reading y_val.csv and converting into numpy array\n",
        "y_val = np.array(pd.read_csv( 'y_val.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eac7dbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "1ae1a1cae3fa4fd0885645102942ea1f",
            "94a9228a6eb04027a0993000ab5bdfbc",
            "705cfa457ff44aedbc63b1b9cca8d05a",
            "0807c570525a44fc8ea5ca93f6934a5d",
            "a178cdc29fbc4fec8fadfd2488377660",
            "f806025fc7874a28885d511a89c2239d",
            "bd116b5f63104e919829d64c88bab3c6",
            "a7755e07d595498a8f08c6127cb58500"
          ]
        },
        "id": "0eac7dbe",
        "outputId": "dae1c80a-a694-4b26-edb0-261017f2edfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of Dataframe is 808.998 MB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae1a1cae3fa4fd0885645102942ea1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory usage after optimization is: 175.730 MB\n",
            "Decreased by 78.3%\n"
          ]
        }
      ],
      "source": [
        "# Reading X_test.csv and reducing memory usage\n",
        "X_test=pd.read_csv(\"X_test.csv\")\n",
        "X_test=reduce_mem_usage(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f567ecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "3dc63881155742768008b9fec5174f63",
            "0a8fc197747e487080eddaf47b636c9f",
            "19c5a155520745c1a12f0b2f58fd4c68",
            "b61ee02e851c48afbbef596ed3ebb5c6",
            "6cd3702a305f4486bd95dce81080d07f",
            "1a8dc8c84af247cf8a7b94e253253344",
            "b497472efd244cb1870f4e0c585c1f44",
            "4547902e6cc6457484140997aaf8e582"
          ]
        },
        "id": "0f567ecd",
        "outputId": "f8364ccc-77cd-4e52-fbc9-f8579490662a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of Dataframe is 5.112 MB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dc63881155742768008b9fec5174f63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory usage after optimization is: 1.919 MB\n",
            "Decreased by 62.5%\n"
          ]
        }
      ],
      "source": [
        "# Reading stores_items.csv\n",
        "stores_items = pd.read_csv('stores_items.csv', index_col=['store_nbr','item_nbr'])\n",
        "\n",
        "# Reading items.csv and setting index as item_nbr\n",
        "items = pd.read_csv( 'items.csv' ).set_index(\"item_nbr\")\n",
        "\n",
        "items = items.reindex( stores_items.index.get_level_values(1) )\n",
        "items=reduce_mem_usage(items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7975cb9",
      "metadata": {
        "id": "b7975cb9"
      },
      "source": [
        "## Part2: Use random forest to select features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a71944b",
      "metadata": {
        "id": "6a71944b"
      },
      "source": [
        "### Defining Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb97dfea",
      "metadata": {
        "id": "cb97dfea"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb  # Correcting the import statement for xgboost\n",
        "\n",
        "def random_forest_feature_selection(X_train, y_train, params, n_days, items):\n",
        "    \"\"\"\n",
        "    Trains multiple XGBoost models to predict sales and returns feature importances.\n",
        "\n",
        "    Args:\n",
        "    X_train: Training feature set.\n",
        "    y_train: Training target variable.\n",
        "    params: Parameters for the XGBoost model.\n",
        "    n_days: Number of days for prediction.\n",
        "    items: Dataset for additional weights.\n",
        "\n",
        "    Returns:\n",
        "    List of feature importances from each trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setting up XGBoost parameters for Random Forest-like behavior\n",
        "    params.update({\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'eta': 1  # Learning rate\n",
        "    })\n",
        "\n",
        "    num_boost_rounds = 1  # Number of boosting rounds\n",
        "    feature_importances_all = []  # Store feature importances from all models\n",
        "\n",
        "    for day in range(16):\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Training step: {day + 1}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Preparing the training data\n",
        "        weights = pd.concat([items[\"perishable\"]] * n_days) * 0.25 + 1\n",
        "        dtrain = xgb.DMatrix(X_train, label=y_train[:, day], weight=weights)\n",
        "        watchlist = [(dtrain, 'train')]\n",
        "\n",
        "        # Training the model\n",
        "        model = xgb.train(params, dtrain, num_boost_rounds, watchlist, verbose_eval=1)\n",
        "\n",
        "        # Extracting and sorting feature importances\n",
        "        feature_importances = model.get_score(importance_type='gain')\n",
        "        sorted_feature_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        feature_importances_all.append(sorted_feature_importances)\n",
        "\n",
        "        # Freeing up memory\n",
        "        del model, dtrain, feature_importances\n",
        "\n",
        "    return feature_importances_all\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f6ac50",
      "metadata": {
        "id": "f8f6ac50"
      },
      "source": [
        "### Feature Selection Using Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff24ca0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ff24ca0b",
        "outputId": "09966615-eff8-4ec4-dcec-1ef475b802f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Step 1\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.502756\n",
            "==================================================\n",
            "Step 2\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.517825\n",
            "==================================================\n",
            "Step 3\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.51848\n",
            "==================================================\n",
            "Step 4\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.535173\n",
            "==================================================\n",
            "Step 5\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.542377\n",
            "==================================================\n",
            "Step 6\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.548207\n",
            "==================================================\n",
            "Step 7\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.541883\n",
            "==================================================\n",
            "Step 8\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.522936\n",
            "==================================================\n",
            "Step 9\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.537185\n",
            "==================================================\n",
            "Step 10\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.530408\n",
            "==================================================\n",
            "Step 11\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.551563\n",
            "==================================================\n",
            "Step 12\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.555245\n",
            "==================================================\n",
            "Step 13\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.554349\n",
            "==================================================\n",
            "Step 14\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.543721\n",
            "==================================================\n",
            "Step 15\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.530702\n",
            "==================================================\n",
            "Step 16\n",
            "==================================================\n",
            "[0]\ttrain-rmse:0.540752\n",
            "CPU times: user 33min 35s, sys: 15min 46s, total: 49min 22s\n",
            "Wall time: 49min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Initialize parameters for the Random Forest model\n",
        "params = {\n",
        "    'max_depth': 15,  # Maximum depth of a tree\n",
        "    'num_parallel_tree': 100  # Number of trees to grow per round\n",
        "}\n",
        "\n",
        "# Define the number of days for the prediction\n",
        "n_days = 2\n",
        "\n",
        "# Call the RandomForest_FeatureSelection function\n",
        "# to get sorted feature importances for all models\n",
        "feature_imp = RandomForest_FeatureSelection(X_train, y_train, params, n_days, items)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2787ff4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2787ff4d",
        "outputId": "6fff9c9d-fc71-43e8-a5c7-94b394c61051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered top 300 features\n"
          ]
        }
      ],
      "source": [
        "top = 300\n",
        "\n",
        "# Using list comprehension for a more concise implementation\n",
        "filtered_features = [\n",
        "    [feature[0] for feature in feature_imp[model][:top]] for model in range(16)\n",
        "]\n",
        "\n",
        "# Using f-string for more modern string formatting\n",
        "print(f\"Filtered top {len(filtered_features[0])} features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7069c86c",
      "metadata": {
        "id": "7069c86c"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "#Saving feature importance\n",
        "with open('300_filtered_features.pkl','wb') as file:\n",
        "    pickle.dump(filtered_features, file)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2bfa4369",
        "2d65c143",
        "825abb64",
        "b7975cb9"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}